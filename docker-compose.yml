name: vllm service
services:
  vllm:
    container_name: vllm
    image: vllm/vllm-openai:latest
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 4
              capabilities: [gpu]
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    environment:
      - HUGGING_FACE_HUB_TOKEN=
      - CUDA_VISIBLE_DEVICES=0,1,2,3
    ports:  
      - "8000:8000"
    ipc: host
    command: >
      --model openai/gpt-oss-20b
      --gpu-memory-utilization 0.8
      --tensor-parallel-size 4
      --max-num-seqs 128
      --max-model-len 8192
      --max-num-batched-tokens 8192


  nginx:
    image: nginx:latest
    container_name: nginx
    ports:
      - "11434:80" # 将11434端口映射到Nginx的80端口
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro # 将Nginx配置文件挂载到容器内
    depends_on:
      - vllm 
